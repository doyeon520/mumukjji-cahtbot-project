{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naver-Blog-URL crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'삼겹살 맛집': ['https://ellisha0706.blog.me/222036196703', 'https://blog.naver.com/musicalyoon?Redirect=Log&logNo=222055437929', 'https://blog.naver.com/woowim?Redirect=Log&logNo=222056167298', 'https://blog.naver.com/hangilchi?Redirect=Log&logNo=222018060805', 'https://kkiibbb.blog.me/222054113153', 'https://blog.naver.com/suyeon052?Redirect=Log&logNo=222060027136', 'https://blog.naver.com/yoo_h_byul?Redirect=Log&logNo=222065835684', 'https://ssomerry.blog.me/222071888269', 'https://blog.naver.com/l_lli?Redirect=Log&logNo=222075941356', 'https://rlacksdyd12.blog.me/222049780675']}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "word = ['삼겹살 맛집']\n",
    "# word = ['삼겹살 맛집', '곱창 맛집', '치킨 맛집']\n",
    "dic = {}\n",
    "\n",
    "for i in word:\n",
    "    #print(i)\n",
    "    n = 1\n",
    "    val = []\n",
    "    for num in range(1): #페이지수(한페이지에 블로그10개씩잇음)\n",
    "        word_encode = urllib.parse.quote(i)\n",
    "        driver = webdriver.Chrome('chromedriver85')\n",
    "        driver.get('https://search.naver.com/search.naver?where=post&sm=tab_jum&query={}&start={}1'.format(word_encode, num))\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        #print(word_encode)\n",
    "        html = driver.page_source\n",
    "        #print(html)\n",
    "        \n",
    "        bs = BeautifulSoup(html, 'html.parser') #문서 파싱 \n",
    "        a = bs.findAll(\"a\", {\"class\":\"sh_blog_title _sp_each_url _sp_each_title\"})\n",
    "        count = 0\n",
    "        driver.close()\n",
    "        \n",
    "        for af in a:\n",
    "            if count < 10: #위에서 정한 페이지수*10\n",
    "                #print(n)\n",
    "                #print(af['href'])\n",
    "                count += 1\n",
    "                n += 1\n",
    "                if 'blog.naver' in af['href'] or 'blog.me' in af['href']: #블로그중에 daum,tistory가 있어서 걸러주도록한다.\n",
    "                    val.append(af['href'])\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    dic[i] = val\n",
    "print(dic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naver-Blog-URL을 이용하여 블로그속의 상호명 crawling\n",
    "## naver는 블로그속에있는 내용 크롤링할때 iframe사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>맛집</th>\n",
       "      <th>주소</th>\n",
       "      <th>상호명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=ell...</td>\n",
       "      <td>[VVERTIGO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=mus...</td>\n",
       "      <td>[맛찬들왕소금구이 포항죽도점]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=woo...</td>\n",
       "      <td>[나무꾼이야기 양곡점]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=han...</td>\n",
       "      <td>[제주이마이가 해운대본점]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=kki...</td>\n",
       "      <td>[안양 늘보리냉삼집]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=suy...</td>\n",
       "      <td>[총각집]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=yoo...</td>\n",
       "      <td>[영통골목식당]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=sso...</td>\n",
       "      <td>[연탄생삼겹고추장구이]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=l_l...</td>\n",
       "      <td>[묵은지생삼겹살]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>삼겹살 맛집</td>\n",
       "      <td>https://blog.naver.com/PostView.nhn?blogId=rla...</td>\n",
       "      <td>[교대이층집 여의도점]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       맛집                                                 주소               상호명\n",
       "0  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=ell...        [VVERTIGO]\n",
       "1  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=mus...  [맛찬들왕소금구이 포항죽도점]\n",
       "2  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=woo...      [나무꾼이야기 양곡점]\n",
       "3  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=han...    [제주이마이가 해운대본점]\n",
       "4  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=kki...       [안양 늘보리냉삼집]\n",
       "5  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=suy...             [총각집]\n",
       "6  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=yoo...          [영통골목식당]\n",
       "7  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=sso...      [연탄생삼겹고추장구이]\n",
       "8  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=l_l...         [묵은지생삼겹살]\n",
       "9  삼겹살 맛집  https://blog.naver.com/PostView.nhn?blogId=rla...      [교대이층집 여의도점]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1'} \n",
    "dataset = pd.DataFrame(columns=['맛집','주소','상호명'])\n",
    "index = 0\n",
    "for w in word:\n",
    "    for mat in dic[w]:\n",
    "        script = []\n",
    "        URL = mat\n",
    "        driver = webdriver.Chrome('./chromedriver85.exe')\n",
    "        driver.get(URL)\n",
    "        html = driver.page_source\n",
    "\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        target_URL = bs.find('iframe').get('src')\n",
    "        target_URL = 'https://blog.naver.com' + target_URL\n",
    "        response = requests.get(target_URL, headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        if soup.findAll('strong', {\"class\": \"se-map-title\"}):\n",
    "            data =soup.find('strong', {\"class\": \"se-map-title\"})\n",
    "            script.append(data.text)\n",
    "            #print(data.text)\n",
    "        elif soup.findAll('span', {\"class\":\"pcol2 fil5\"}):\n",
    "            data =soup.find('span', {\"class\":\"pcol2 fil5\"})\n",
    "            script.append(data.text)\n",
    "            #print(data.text)    \n",
    "        else:\n",
    "            script.append(None)\n",
    "            #print('none')\n",
    "        driver.close()\n",
    "        #for txt_line in data:\n",
    "        #    script.append(txt_line)\n",
    "        dataset.loc[index] = [w, target_URL, script]\n",
    "        print(index) #잘 되고있는지 확인하기 위해,,ㅎ\n",
    "        index+= 1\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.to_csv('list1.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
